{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Notebook for scraping popular baby names in the US from US Social Security Webpage\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the URL of the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ssa.gov/cgi-bin/namesbystate.cgi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining helper function for extracting state names from page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_extractor(soup):\n",
    "    states = []\n",
    "    for s in soup.find_all('form'):\n",
    "        for option in s.find_all('option'):\n",
    "            states.append(option.text)\n",
    "    \n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = state_extractor(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining helper function for extracting names, gender and numbers from page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_extractor(soup, year, state):    \n",
    "    rank = []\n",
    "    name = []\n",
    "    male_name = []\n",
    "    male_num = []\n",
    "    female_name = []\n",
    "    female_num = []\n",
    "    gender1 = []\n",
    "    gender2 = []\n",
    "    \n",
    "    for table1 in soup.find_all('table'):\n",
    "        for table2 in table1.find_all('table')[1:]:\n",
    "            for tds in table2.find_all('tr')[1:]:\n",
    "                data = tds.text.split('\\n')\n",
    "                rank.append(data[0])\n",
    "                male_name.append(data[1])\n",
    "                male_num.append(data[2])\n",
    "                gender1.append('male')\n",
    "                female_name.append(data[3])\n",
    "                female_num.append(data[4])\n",
    "                gender2.append('female')\n",
    "\n",
    "    males = pd.DataFrame({'rank':rank,'name':male_name, 'num':male_num, 'gender':gender1})\n",
    "    females = pd.DataFrame({'rank':rank,'name':female_name, 'num':female_num, 'gender':gender2})\n",
    "    result = pd.concat([males, females])\n",
    "    result['year'] = year\n",
    "    result['state'] = state\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the Web Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(executable_path='/Users/anirudhchandra/AnacondaProjects/WebDriver/chromedriver')\n",
    "browser.get(url)\n",
    "\n",
    "years = np.arange(2000,2019).astype(str).tolist()\n",
    "states = states\n",
    "result = pd.DataFrame([], columns=['rank','name','num','year','state'])\n",
    "\n",
    "for year in years:\n",
    "    for state in states:\n",
    "        \n",
    "        #Select state\n",
    "        state_path = \"//select[@name='state']/option[text()=\" + \"'\" + state + \"']\"\n",
    "        browser.find_element_by_xpath(state_path).click()\n",
    "        \n",
    "        #Locate the Year entry form, clear it and enter new year\n",
    "        find_year_entry = browser.find_element_by_id('year')\n",
    "        clear_year_entry = find_year_entry.clear()\n",
    "        find_year_entry.send_keys(year)\n",
    "\n",
    "        #Click 'GO' button to search\n",
    "        go_button = browser.find_element_by_xpath(\"//input[@type='submit']\")\n",
    "        go_button.click()\n",
    "        \n",
    "        #Parsing the page for names\n",
    "        soup = BeautifulSoup(browser.page_source)\n",
    "        output = name_extractor(soup, year, state)\n",
    "        result = pd.concat([result, output],axis=0)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of Scraped Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 193800 entries, 0 to 99\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   rank    193800 non-null  object\n",
      " 1   name    193800 non-null  object\n",
      " 2   num     193800 non-null  object\n",
      " 3   year    193800 non-null  object\n",
      " 4   state   193800 non-null  object\n",
      " 5   gender  193800 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 10.4+ MB\n"
     ]
    }
   ],
   "source": [
    "result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the results as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('usa_top_names.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
